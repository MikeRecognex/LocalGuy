---
title: Ring-1T-2.5 Released with SOTA Deep Thinking Performance
date: 2026-02-13
description: inclusionAI releases Ring-1T-2.5 in FP8 format, claiming state-of-the-art performance on deep thinking tasks with optimized quantization for local deployment.
tags:
  - quantization
  - fp8
  - reasoning
  - open-source
status: draft
---
inclusionAI has released [Ring-1T-2.5](https://huggingface.co/inclusionAI/Ring-1T-2.5-FP8), positioning it as achieving state-of-the-art performance on deep thinking and reasoning tasks. The model is distributed in FP8 format, representing significant memory optimization for local deployment scenarios.

FP8 quantization offers substantial benefits for local LLM practitioners, providing roughly 2x memory reduction compared to FP16 while maintaining much of the model's reasoning capabilities. This makes larger models accessible on consumer hardware that would otherwise struggle with memory constraints.

The focus on "deep thinking" suggests this model excels at multi-step reasoning tasks, making it particularly valuable for complex problem-solving applications. The FP8 release format indicates the developers prioritized local deployment efficiency, recognizing the growing demand for high-capability models that can run on accessible hardware.

---
*Source: [r/LocalLLaMA](https://huggingface.co/inclusionAI/Ring-1T-2.5-FP8) Â· Relevance: 7/10*
